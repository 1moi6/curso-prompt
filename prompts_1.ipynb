{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import openai\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_key_1 = config['CURSO_PROMPT']['api_key']\n",
    "openai.api_key = api_key_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você deve expressar o que deseja que um modelo faça fornecendo instruções o mais claras e específicas possível, o que guiará o modelo em direção à saída desejada e reduzirá as chances de receber respostas irrelevantes ou incorretas, não confundindo a escrita de uma solicitação clara com a escrita de uma solicitação curta, pois em muitos casos, solicitações mais longas fornecem mais clareza e contexto para o modelo, o que pode levar a saídas mais detalhadas e relevantes.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "traduza para o português o texto delilimitado pelas por aterisco\n",
    "into a single sentence.\n",
    "*{text}* \n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"book_id\": 1,\n",
      "    \"titulo\": \"O Segredo do Jardim\",\n",
      "    \"autor\": \"Ana Silva\",\n",
      "    \"genero\": \"Romance\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 2,\n",
      "    \"titulo\": \"A Última Carta\",\n",
      "    \"autor\": \"Pedro Santos\",\n",
      "    \"genero\": \"Drama\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": 3,\n",
      "    \"titulo\": \"O Mistério da Floresta\",\n",
      "    \"autor\": \"Mariana Oliveira\",\n",
      "    \"genero\": \"Suspense\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Crie uma lista com três títulos de livros inventados com título, autor e gênero. \n",
    "Apresente-os em formato JSON com as seguintes chaves: \n",
    "book_id, titulo, autor, genero.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
